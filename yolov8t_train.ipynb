{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829784a0-2f46-494f-b34a-4dad4446ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.7 🚀 Python-3.11.7 torch-2.1.2+cu121 CUDA:0 (NVIDIA RTX A5000, 24040MiB)\n",
      "Setup complete ✅ (11 CPUs, 116.4 GB RAM, 13.5/64.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "ultralytics.checks()\n",
    "import wandb\n",
    "import random  # for demo script\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553ad282-cef2-4221-b1d7-f39e8aeea630",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/work/csr33/object_detection\")\n",
    "# Update settings\n",
    "# https://docs.ultralytics.com/quickstart/\n",
    "os.makedirs('/work/csr33/object_detection/weights', exist_ok=True)\n",
    "settings.update({'weights_dir': '/work/csr33/object_detection/weights'})\n",
    "\n",
    "os.makedirs('/work/csr33/object_detection/runs', exist_ok=True)\n",
    "settings.update({'runs_dir': '/work/csr33/object_detection/runs'})\n",
    "\n",
    "settings.update({'neptune': False, 'clearml': False, \n",
    "                 \"raytune\": False, #'comet': True, 'raytune': True,\n",
    "                 'dvc': False, 'hub': False, 'mlflow': False,\n",
    "                 'tensorboard': False, 'wandb': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db8186fc-52ba-44da-a2e1-2fe2788027da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /hpc/home/csr33/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up wandb\n",
    "WANDB_API_KEY=\"006286beb62f8eedc5994d45a84434bf72b09040\"\n",
    "# Name and notes optional\n",
    "WANDB_NAME=\"My first run\"\n",
    "WANDB_NOTES=\"Smaller learning rate, more regularization.\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f77ea0-8ba6-4740-b6e3-6ad2a993669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parse():\n",
    "    parser = argparse.ArgumentParser(\"Exploratory Data Analysis\")\n",
    "    parser.add_argument(\"--data\", default=\"/hpc/home/csr33/ast_object_detection/ast.yaml\", type=str)\n",
    "    parser.add_argument(\"--model\", default='yolov8n.pt', type=str)\n",
    "    parser.add_argument(\"--batch\", default=8, type=int)\n",
    "    parser.add_argument(\"--imgsz\", default=640, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=2, type=int)\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cf551b-c9fa-4bda-9276-b32c064a8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['my_notebook']\n",
    "args = get_args_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6394a7-98c2-4591-9e3c-271be98f2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameter_yaml = \"/work/csr33/object_detection/runs/detect/tune3/best_hyperparameters.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b91d53c-5cce-415a-8c0c-9b971d6f4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO('yolov8x.pt')  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639916e-932b-4e67-9bd6-f6bd76f2d23e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.9 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.7 🚀 Python-3.11.7 torch-2.1.2+cu121 CUDA:0 (NVIDIA RTX A5000, 24040MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=/hpc/home/csr33/ast_object_detection/ast.yaml, epochs=2, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=yolov8n_e2_b8_imgsz6402, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=/work/csr33/object_detection/runs/detect/tune3/best_hyperparameters.yaml, tracker=botsort.yaml, save_dir=/work/csr33/object_detection/runs/detect/yolov8n_e2_b8_imgsz6402\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8724709  ultralytics.nn.modules.head.Detect           [7, [320, 640, 640]]          \n",
      "Model summary: 365 layers, 68159349 parameters, 68159333 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcsr33\u001b[0m (\u001b[33mturn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/csr33/object_detection/wandb/run-20240202_114753-joec2z9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/turn/YOLOv8/runs/joec2z9t' target=\"_blank\">yolov8n_e2_b8_imgsz6402</a></strong> to <a href='https://wandb.ai/turn/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/turn/YOLOv8' target=\"_blank\">https://wandb.ai/turn/YOLOv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/turn/YOLOv8/runs/joec2z9t' target=\"_blank\">https://wandb.ai/turn/YOLOv8/runs/joec2z9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /work/csr33/ast/datasets/ast_yolov5/labels/train.cache... 19347 images, 0 backgrounds, 0 corrupt: 100%|██████████| 19347/19347 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /work/csr33/ast/datasets/ast_yolov5/images/train/m_3812263_se_10_060_20180723_15_18.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /work/csr33/ast/datasets/ast_yolov5/labels/val.cache... 4146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4146/4146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /work/csr33/ast/datasets/ast_yolov5/images/val/m_3809031_sw_15_060_20181121_04_01.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/hpc/group/borsuklab/cred/.conda/envs/yolov8_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /work/csr33/object_detection/runs/detect/yolov8n_e2_b8_imgsz6402/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/work/csr33/object_detection/runs/detect/yolov8n_e2_b8_imgsz6402\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2      7.27G      1.038      1.074          1         44        640: 100%|██████████| 2419/2419 [10:06<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 260/260 [00:49<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4146      21256      0.652      0.538      0.522      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/2      7.58G     0.9844     0.8512     0.9852         34        640:  16%|█▌        | 378/2419 [01:29<07:43,  4.40it/s]"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "   data=args.data,\n",
    "   imgsz=args.imgsz,\n",
    "   epochs=args.epochs,\n",
    "   batch=args.batch,\n",
    "    workers=4,\n",
    "    cfg = best_hyper_parameter_yaml,\n",
    "   name=f'{os.path.splitext(args.model)[0]}_e{args.epochs}_b{args.batch}_imgsz{args.imgsz}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19352d0-ccdf-4648-a54c-d00f1c6da617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "results = model.val()  # evaluate model performance on the validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8 env",
   "language": "python",
   "name": "yolov8_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
