{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "27ca383c-0a97-4679-f1c5-ba843f033de7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import ast\n",
    "from copy import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pyproj import Proj\n",
    "from shapely.ops import transform\n",
    "\n",
    "import pyproj\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "#ultralytics.checks()\n",
    "import rioxarray\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import concurrent.futures\n",
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parse():\n",
    "    parser = argparse.ArgumentParser(\"\")    \n",
    "    parser.add_argument(\"--processing_naip_dir\", default=\"/work/csr33/images_for_predictions/processed_naip_data\", type=str)\n",
    "    parser.add_argument(\"--processing_naip_filename\", default=\"processed_naip_data\", type=str)\n",
    "    parser.add_argument(\"--chunk_id\",  type=int)\n",
    "    parser.add_argument(\"--tile_dir\", default=\"/work/csr33/images_for_predictions/naip_tiles\", type=str)\n",
    "    parser.add_argument(\"--tilename_chunks_path\", default='/hpc/home/csr33/ast_object_detection/images_for_prediction/tilename_chunks.npz', type=str)\n",
    "\n",
    "    parser.add_argument(\"--model_path\", default=\"/work/csr33/object_detection/runs/detect/baseline_train/weights/best.pt\", type=str)\n",
    "    parser.add_argument(\"--prediction_dir\", default=\"/work/csr33/images_for_predictions/predictions\", type=str)\n",
    "    parser.add_argument(\"--prediction_filename\", default=\"predictions\", type=str)\n",
    "    parser.add_argument(\"--imgsz\", default=640, type=int)\n",
    "    parser.add_argument('--img_dir', type=str, default=\"/work/csr33/images_for_predictions/naip_imgs\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['my_notebook']\n",
    "args = get_args_parse()\n",
    "args.chunk_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_names = os.listdir(args.tile_dir)\n",
    "tile_names = [os.path.splitext(tile_name)[0] for tile_name in tile_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_3308052_se_17_060_20210501\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tile_dimensions_and_utm_coords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m tile_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mtile_dir, tile_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# specify the tile path\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#obtain tile information\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m utmx, utmy, utm_proj, tile_band, tile_height, tile_width \u001b[38;5;241m=\u001b[39m \u001b[43mtile_dimensions_and_utm_coords\u001b[49m(tile_path) \u001b[38;5;66;03m#used\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#predict on images\u001b[39;00m\n\u001b[1;32m     19\u001b[0m predict_df_by_tank \u001b[38;5;241m=\u001b[39m predict_process(img_paths, tile_height, tile_width, args)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tile_dimensions_and_utm_coords' is not defined"
     ]
    }
   ],
   "source": [
    "#create directory to store results\n",
    "os.makedirs(args.prediction_dir, exist_ok=True)\n",
    "# load model\n",
    "model = YOLO(args.model_path)  # custom trained model \n",
    "# load a subset of the tile paths to predict on\n",
    "tile_paths = np.load(args.tilename_chunks_path)[str(args.chunk_id)]\n",
    "tile_names = [os.path.splitext(os.path.basename(tile_path))[0] for tile_path in tile_paths]\n",
    "#intialize dataframes\n",
    "predict_df = pd.DataFrame({})\n",
    "merged_df = pd.DataFrame({})\n",
    "\n",
    "for tile_name in tile_names:\n",
    "    print(tile_name)\n",
    "    img_paths = glob(os.path.join(args.img_dir,\"*\"+tile_name+\"*\")) #identify the imgs correspondig to a given tile\n",
    "    tile_path = os.path.join(args.tile_dir, tile_name +\".tif\") # specify the tile path\n",
    "    #obtain tile information\n",
    "    utmx, utmy, utm_proj, tile_band, tile_height, tile_width = tile_dimensions_and_utm_coords(tile_path) #used\n",
    "    #predict on images\n",
    "    predict_df_by_tank = predict_process(img_paths, tile_height, tile_width, args)\n",
    "    #merge neighboring images\n",
    "    merged_df_by_tank = merge_predicted_bboxes(predict_df_by_tank, dist_limit = 5)\n",
    "    # calculate utm and lat lon coords\n",
    "    merged_df_by_tank[[\"utm_coords\",\"latlon_coords\"]] = merged_df_by_tank[\"bbox_pixel_coords\"].apply(\\\n",
    "                                                        lambda box: get_crs_coords(box, utmx, utmy, utm_proj))\n",
    "    #specify the projection used \n",
    "    merged_df_by_tank[\"utm_proj\"] = [utm_proj] * len(merged_df_by_tank)\n",
    "    \n",
    "    #update dataframes\n",
    "    predict_df = pd.concat([predict_df, predict_df_by_tank], ignore_index=True)\n",
    "    merged_df = pd.concat([merged_df, merged_df_by_tank], ignore_index=True)\n",
    "    #delete temp dataframe to conserve memory\n",
    "    del predict_df_by_tank, merged_df_by_tank\n",
    "    \n",
    "predict_df.to_file(os.path.join(args.prediction_dir, f\"predictions_{args.chunk_id}.geojson\"), driver='GeoJSON')\n",
    "merged_df.to_file(os.path.join(args.prediction_dir, f\"merged_predictions_{args.chunk_id}.geojson\"), driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_3308052_se_17_060_20210501\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 31.40 GiB of which 106.12 MiB is free. Process 1391294 has 23.89 GiB memory in use. Including non-PyTorch memory, this process has 7.39 GiB memory in use. Of the allocated memory 6.64 GiB is allocated by PyTorch, and 343.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m tile_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mtile_dir, tile_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m utmx, utmy, utm_proj, tile_band, tile_height, tile_width \u001b[38;5;241m=\u001b[39m tile_dimensions_and_utm_coords(tile_path) \u001b[38;5;66;03m#used\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predict_df_by_tank \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtile_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m merged_df_by_tank \u001b[38;5;241m=\u001b[39m merge_predicted_bboxes(predict_df_by_tank, dist_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# calculate lat lon\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 67\u001b[0m, in \u001b[0;36mpredict_process\u001b[0;34m(img_paths, tile_height, tile_width, args)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df_chunk \u001b[38;5;129;01min\u001b[39;00m chunk_df(img_paths, num_chunks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     66\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 67\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, conf=0.5)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m#process_results(results, utmx, utmy, utm_proj, tile_height, tile_width, item_dim=args.imgsz)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, process_results(results, tile_height, tile_width, item_dim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mimgsz)])\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/engine/model.py:406\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/engine/predictor.py:204\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/engine/predictor.py:283\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 283\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/engine/predictor.py:140\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    136\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    139\u001b[0m )\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:384\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    381\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/tasks.py:80\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/tasks.py:98\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/tasks.py:119\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    120\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:221\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 221\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:221\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 221\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:331\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hpc/group/borsuklab/cred/.conda/envs/yolov8/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 31.40 GiB of which 106.12 MiB is free. Process 1391294 has 23.89 GiB memory in use. Including non-PyTorch memory, this process has 7.39 GiB memory in use. Of the allocated memory 6.64 GiB is allocated by PyTorch, and 343.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_bools, merged_characteristics, merged_bboxes = merge_algo(trunc_diff_objs_characteristics,\n",
    "                                                                 trunc_diff_objs_bboxes, distance_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utm_coords</th>\n",
       "      <th>latlon_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[446818.95, 3395365.95, 447778.95, 3395365.95]</td>\n",
       "      <td>[-87.55527460131331, 30.689886742888532, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[449375.25, 3394682.5500000003, 452412.15, 339...</td>\n",
       "      <td>[-87.528551119962, 30.683831591277624, -87.496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[446283.45, 3389130.1500000004, 446667.45, 338...</td>\n",
       "      <td>[-87.56054080717084, 30.633595455653165, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[448987.35000000003, 3392431.95, 452059.350000...</td>\n",
       "      <td>[-87.53248946454238, 30.663507236118058, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[448990.65, 3392430.45, 452062.65, 3389550.45]</td>\n",
       "      <td>[-87.53245494493166, 30.66349384229714, -87.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[447626.85000000003, 3388437.7500000005, 44935...</td>\n",
       "      <td>[-87.54648764493402, 30.627407377589865, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[447626.55000000005, 3388435.6500000004, 44935...</td>\n",
       "      <td>[-87.54649066868814, 30.627388415436897, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[447626.25, 3388434.1500000004, 449354.25, 338...</td>\n",
       "      <td>[-87.54649372286299, 30.62737486728348, -87.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[446148.45, 3391811.5500000003, 446340.45, 338...</td>\n",
       "      <td>[-87.56208941625928, 30.657784407948782, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[447182.85000000003, 3389281.35, 448526.850000...</td>\n",
       "      <td>[-87.55116352677712, 30.63499990001919, -87.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[447120.75, 3390836.85, 448272.75, 3387849.750...</td>\n",
       "      <td>[-87.55189122267936, 30.649032901445267, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[448178.55000000005, 3392341.95, 450482.550000...</td>\n",
       "      <td>[-87.54092718914352, 30.66266027384162, -87.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[448179.15, 3394375.6500000004, 450483.15, 339...</td>\n",
       "      <td>[-87.54102318001047, 30.681010942970545, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[448177.35000000003, 3394377.1500000004, 45048...</td>\n",
       "      <td>[-87.5410420472302, 30.68102439961016, -87.516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[447648.75, 3392474.2500000005, 449376.75, 338...</td>\n",
       "      <td>[-87.54646390015408, 30.663830918863468, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[449645.55000000005, 3389115.7500000005, 45241...</td>\n",
       "      <td>[-87.52545733680677, 30.633612024081344, -87.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[450669.45, 3394874.2500000005, 452412.15, 339...</td>\n",
       "      <td>[-87.51504858494705, 30.685615630498994, -87.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[447370.35000000003, 3390210.45, 448714.350000...</td>\n",
       "      <td>[-87.54925434774212, 30.64339173821601, -87.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[449398.65, 3394480.6500000004, 452412.15, 339...</td>\n",
       "      <td>[-87.52829690137261, 30.682010784292853, -87.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[447532.35000000003, 3391996.95, 449068.350000...</td>\n",
       "      <td>[-87.54765459894008, 30.659518990995736, -87.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[447529.65, 3391996.95, 449065.65, 3388540.95]</td>\n",
       "      <td>[-87.5476827803148, 30.65951887224065, -87.531...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[451309.65, 3395165.5500000003, 452412.15, 339...</td>\n",
       "      <td>[-87.50837840371236, 30.688270448716253, -87.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[447106.35000000003, 3389702.5500000003, 44825...</td>\n",
       "      <td>[-87.55198337550796, 30.638797132497714, -87.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utm_coords  \\\n",
       "0      [446818.95, 3395365.95, 447778.95, 3395365.95]   \n",
       "1   [449375.25, 3394682.5500000003, 452412.15, 339...   \n",
       "2   [446283.45, 3389130.1500000004, 446667.45, 338...   \n",
       "3   [448987.35000000003, 3392431.95, 452059.350000...   \n",
       "4      [448990.65, 3392430.45, 452062.65, 3389550.45]   \n",
       "5   [447626.85000000003, 3388437.7500000005, 44935...   \n",
       "6   [447626.55000000005, 3388435.6500000004, 44935...   \n",
       "7   [447626.25, 3388434.1500000004, 449354.25, 338...   \n",
       "8   [446148.45, 3391811.5500000003, 446340.45, 338...   \n",
       "9   [447182.85000000003, 3389281.35, 448526.850000...   \n",
       "10  [447120.75, 3390836.85, 448272.75, 3387849.750...   \n",
       "11  [448178.55000000005, 3392341.95, 450482.550000...   \n",
       "12  [448179.15, 3394375.6500000004, 450483.15, 339...   \n",
       "13  [448177.35000000003, 3394377.1500000004, 45048...   \n",
       "14  [447648.75, 3392474.2500000005, 449376.75, 338...   \n",
       "15  [449645.55000000005, 3389115.7500000005, 45241...   \n",
       "16  [450669.45, 3394874.2500000005, 452412.15, 339...   \n",
       "17  [447370.35000000003, 3390210.45, 448714.350000...   \n",
       "18  [449398.65, 3394480.6500000004, 452412.15, 339...   \n",
       "19  [447532.35000000003, 3391996.95, 449068.350000...   \n",
       "20     [447529.65, 3391996.95, 449065.65, 3388540.95]   \n",
       "21  [451309.65, 3395165.5500000003, 452412.15, 339...   \n",
       "22  [447106.35000000003, 3389702.5500000003, 44825...   \n",
       "\n",
       "                                        latlon_coords  \n",
       "0   [-87.55527460131331, 30.689886742888532, -87.5...  \n",
       "1   [-87.528551119962, 30.683831591277624, -87.496...  \n",
       "2   [-87.56054080717084, 30.633595455653165, -87.5...  \n",
       "3   [-87.53248946454238, 30.663507236118058, -87.5...  \n",
       "4   [-87.53245494493166, 30.66349384229714, -87.50...  \n",
       "5   [-87.54648764493402, 30.627407377589865, -87.5...  \n",
       "6   [-87.54649066868814, 30.627388415436897, -87.5...  \n",
       "7   [-87.54649372286299, 30.62737486728348, -87.52...  \n",
       "8   [-87.56208941625928, 30.657784407948782, -87.5...  \n",
       "9   [-87.55116352677712, 30.63499990001919, -87.53...  \n",
       "10  [-87.55189122267936, 30.649032901445267, -87.5...  \n",
       "11  [-87.54092718914352, 30.66266027384162, -87.51...  \n",
       "12  [-87.54102318001047, 30.681010942970545, -87.5...  \n",
       "13  [-87.5410420472302, 30.68102439961016, -87.516...  \n",
       "14  [-87.54646390015408, 30.663830918863468, -87.5...  \n",
       "15  [-87.52545733680677, 30.633612024081344, -87.4...  \n",
       "16  [-87.51504858494705, 30.685615630498994, -87.4...  \n",
       "17  [-87.54925434774212, 30.64339173821601, -87.53...  \n",
       "18  [-87.52829690137261, 30.682010784292853, -87.4...  \n",
       "19  [-87.54765459894008, 30.659518990995736, -87.5...  \n",
       "20  [-87.5476827803148, 30.65951887224065, -87.531...  \n",
       "21  [-87.50837840371236, 30.688270448716253, -87.4...  \n",
       "22  [-87.55198337550796, 30.638797132497714, -87.5...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " merged_df_by_tank[\"bbox_pixel_coords\"].apply(lambda box: get_crs_coords(box, utmx, utmy, utm_proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'external_floating_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'undefined_object',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'external_floating_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank',\n",
       " 'narrow_closed_roof_tank']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({:class_names\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[...]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def merge_algo(characteristics, bboxes, dist_limit): #used\n",
    "    merge_bools = [False] * len(characteristics)\n",
    "    for i, (char1, bbox1) in enumerate(zip(characteristics, bboxes)):\n",
    "        for j, (char2, bbox2) in enumerate(zip(characteristics, bboxes)):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            # Create a new box if a distances is less than disctance limit defined \n",
    "            merge_bool = calc_sim(bbox1, bbox2, dist_limit) \n",
    "            if merge_bool == True:\n",
    "            # Create a new box  \n",
    "                new_box = merge_boxes(bbox1, bbox2)   \n",
    "                bboxes[i] = new_box\n",
    "                #delete previous text boxes\n",
    "                del bboxes[j]\n",
    "                \n",
    "                # Create a new text string\n",
    "                ##chip_name list\n",
    "                if char1[0] != char2[0]: #if the chip_names are not the same\n",
    "                    #make chip_names into an array\n",
    "                    if type(char1[0]) == str: \n",
    "                        chip_names_1 = np.array([char1[0]])\n",
    "                    if type(char2[0]) == str:\n",
    "                        chip_names_2 = np.array([char2[0]])\n",
    "                    chip_names = np.concatenate((chip_names_1, chip_names_2), axis=0)\n",
    "                    chip_names = np.unique(chip_names).tolist()\n",
    "                else:\n",
    "                    chip_names = np.unique(char1[0]).tolist()  #if the chip_names are not the same\n",
    "                \n",
    "                #get object type \n",
    "                if char1[1] != char2[1]:\n",
    "                    object_type = 'undefined_object'\n",
    "                object_type = char1[1]\n",
    "                \n",
    "                characteristics[i] = [chip_names, object_type, 'Unspecified', '1', '1']\n",
    "                #delete previous text \n",
    "                del characteristics[j]\n",
    "                \n",
    "                #return a new boxes and new text string that are close\n",
    "                merge_bools[i] = True\n",
    "    return merge_bools, characteristics, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_proj = get_utm_proj(tile_path)\n",
    "utm_projection_tile.append(utm_proj)\n",
    "#specify tile chracteristics\n",
    "tile_heights.append(tile_height)\n",
    "tile_widths.append(tile_width)\n",
    "tile_depths.append(tile_band)\n",
    "#specify lat lon \n",
    "nw_lon, nw_lat = transform_point_utm_to_wgs84(utm_proj, utmx[0], utmy[0])\n",
    "se_lon, se_lat = transform_point_utm_to_wgs84(utm_proj, utmx[-1], utmy[-1]) \n",
    "nw_lon_tile.append(nw_lon) #NW_coordinates #minlon\n",
    "nw_lat_tile.append(nw_lat) #NW_coordinates #maxlat\n",
    "se_lon_tile.append(se_lon) #SE_coordinates #maxlon\n",
    "se_lat_tile.append(se_lat) #SE_coordinates #minlat\n",
    "\n",
    "for positive_image in positive_images: #iterate over each image affiliated with a given tile\n",
    "    #tile and chip names\n",
    "    image_name = os.path.splitext(positive_image)[0]\n",
    "    image_names.append(image_name) # The index is a six-digit number like '000023'.\n",
    "    tile_names_by_chip.append(tile_name)\n",
    "    #row/col indicies \n",
    "    y, x = image_name.split(\"_\")[-2:] #name of tif with the extension removed; y=row;x=col\n",
    "    y = int(y)\n",
    "    x = int(x)\n",
    "    row_indicies.append(y)\n",
    "    col_indicies.append(x)\n",
    "    #get the pixel coordinates (indexing starting at 0)\n",
    "    minx = x*item_dim \n",
    "    miny = y*item_dim \n",
    "    maxx = (x+1)*item_dim - 1\n",
    "    maxy = (y+1)*item_dim - 1\n",
    "    if maxx > tile_width:\n",
    "        maxx = tile_width - 1\n",
    "    if maxy > tile_height:\n",
    "        maxy = tile_height - 1\n",
    "    minx_pixel.append(minx) #NW (max: Top Left) # used for numpy crop\n",
    "    miny_pixel.append(miny) #NW (max: Top Left) # used for numpy crop\n",
    "    maxx_pixel.append(maxx) #SE (min: Bottom right) \n",
    "    maxy_pixel.append(maxy) #SE (min: Bottom right) \n",
    "    #image utm coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_objects(xml_directory, tile_name, obj_class, obj_truncated, obj_difficult, obj_chip_name,\n",
    "                obj_xmin, obj_ymin, obj_xmax, obj_ymax): #used\n",
    "    tree = et.parse(os.path.join(xml_directory, tile_name + \".xml\"))\n",
    "    root = tree.getroot() \n",
    "    obj = et.Element(\"object\") #add size to xml\n",
    "    \n",
    "    name = et.Element(\"name\") #class\n",
    "    name.text = str(obj_class) \n",
    "    obj.insert(0, name)\n",
    "    \n",
    "    pose = et.Element(\"pose\") #pose\n",
    "    pose.text = \"Unspecified\" \n",
    "    obj.insert(1, pose)\n",
    "    \n",
    "    truncated = et.Element(\"truncated\")\n",
    "    truncated.text = str(obj_truncated)\n",
    "    obj.insert(2, truncated)\n",
    "\n",
    "    difficult = et.Element(\"difficult\")\n",
    "    difficult.text = str(obj_difficult)\n",
    "    obj.insert(3, difficult)\n",
    " \n",
    "    chip_name = et.Element(\"chip_name\")\n",
    "    chip_name.text = str(obj_chip_name)\n",
    "    obj.insert(4, chip_name)\n",
    "\n",
    "    bndbox = et.Element(\"bndbox\") #bounding box\n",
    "    xmin = et.Element(\"xmin\") #xmin\n",
    "    xmin.text = str(obj_xmin) \n",
    "    bndbox.insert(0, xmin)\n",
    "    ymin = et.Element(\"ymin\") #ymin\n",
    "    ymin.text = str(obj_ymin) \n",
    "    bndbox.insert(1, ymin)\n",
    "    xmax = et.Element(\"xmax\") #xmax\n",
    "    xmax.text = str(obj_xmax) \n",
    "    bndbox.insert(2, xmax)\n",
    "    ymax = et.Element(\"ymax\") #ymax\n",
    "    ymax.text = str(obj_ymax) \n",
    "    bndbox.insert(3, ymax)\n",
    "    obj.insert(5, bndbox)\n",
    "    \n",
    "    root.append(obj)\n",
    "    tree = et.ElementTree(root)\n",
    "    et.indent(tree, space=\"\\t\", level=0)\n",
    "    tree.write(os.path.join(xml_directory, tile_name +\".xml\"))   \n",
    "\n",
    "\n",
    "def generate_tile_xmls(images_and_xmls_by_tile_dir, tile_dir, xml_folder_name, tiles_xml_dir, item_dim): #used\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        images_and_xmls_by_tile_dir(str): path to directory containing folders holding annotations and images\n",
    "        tile_dir(str): path to directory containing tiles\n",
    "        \n",
    "    Returns:\n",
    "        object:\n",
    "    \"\"\"\n",
    "    tile_names = [f for f in os.listdir(images_and_xmls_by_tile_dir) \\\n",
    "                  if len(glob(os.path.join(images_and_xmls_by_tile_dir, f, \"**/*.xml\"))) > 0]\n",
    "    for tile_name in tqdm(tile_names):\n",
    "        tile_name_ext = tile_name + \".tif\"\n",
    "        #get tile dimensions ##replace with information from tile characteristics\n",
    "        da = rioxarray.open_rasterio(os.path.join(tile_dir, tile_name_ext))\n",
    "        tile_band, tile_height, tile_width = da.shape[0], da.shape[1], da.shape[2]\n",
    "        #specify xml paths for each tile\n",
    "        positive_xml_dir = os.path.join(images_and_xmls_by_tile_dir, tile_name, xml_folder_name)\n",
    "        #load a list of images/xmls for each tile\n",
    "        positive_xmls = os.listdir(positive_xml_dir)\n",
    "                       \n",
    "        for index, chip_xml in enumerate(positive_xmls): #iterate over positive xmls\n",
    "            #load each chipped image xml\n",
    "            tree = et.parse(os.path.join(positive_xml_dir, chip_xml))\n",
    "            root = tree.getroot()\n",
    "\n",
    "            #create the tile xml\n",
    "            if index == 0:\n",
    "                resolution = root.find('resolution').text\n",
    "                capture_date = root.find('capture_date').text\n",
    "                create_tile_xml(tile_name, tiles_xml_dir, resolution, capture_date, tile_width, tile_height, tile_band)\n",
    "\n",
    "            #identify rows and columns\n",
    "            chip_name = os.path.splitext(chip_xml)[0]\n",
    "            y, x = chip_name.split(\"_\")[-2:] #name of tif with the extension removed; y=row;x=col\n",
    "            # Each chip xml goes from 1 - 512, specify the \"0\", or the end point of the last xml\n",
    "            minx = int(x)*item_dim\n",
    "            miny = int(y)*item_dim\n",
    "\n",
    "            #add the bounding boxes\n",
    "            for obj in root.iter('object'):\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                obj_xmin = str(minx + int(xmlbox.find('xmin').text))\n",
    "                obj_xmax = str(minx + int(xmlbox.find('xmax').text))\n",
    "                obj_ymin = str(miny + int(xmlbox.find('ymin').text))\n",
    "                obj_ymax = str(miny + int(xmlbox.find('ymax').text))\n",
    "                # correct bboxes that extend past the bounds of the tile width/height\n",
    "                if int(obj_xmin) > tile_width:\n",
    "                    obj_xmin = str(tile_width)\n",
    "                if int(obj_xmax) > tile_width:\n",
    "                    obj_xmax = str(tile_width)\n",
    "                if int(obj_ymin) > tile_height:\n",
    "                    obj_ymin = str(tile_height)\n",
    "                if int(obj_ymax) > tile_height:\n",
    "                    obj_ymax = str(tile_height)\n",
    "                add_objects(tiles_xml_dir, tile_name, obj.find('name').text, obj.find('truncated').text,\n",
    "                            obj.find('difficult').text, chip_name, obj_xmin, obj_ymin, obj_xmax, obj_ymax)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "def calc_sim(bbox1, bbox2, dist_limit): #used\n",
    "    \"\"\"Determine the similarity of distances between bboxes to determine whether bboxes should be merged\n",
    "    Computer a Matrix similarity of distances of the text and object\n",
    "    Called in merge_algo\n",
    "    Arg:\n",
    "    bbox1(list): a list of the (xmin, ymin, xmax, ymax) coordinates for box 1 \n",
    "    bbox2(list): a list of the (xmin, ymin, xmax, ymax) coordinates for box 2\n",
    "    dist_list(int): the maximum threshold (pixel distance) to merge bounding boxes\n",
    "    Returns:\n",
    "    (bool): to indicate whether the bboxes should be merged \n",
    "    \"\"\"\n",
    "\n",
    "    # text: ymin, xmin, ymax, xmax\n",
    "    # obj: ymin, xmin, ymax, xmax\n",
    "    bbox1_xmin, bbox1_ymin, bbox1_xmax, bbox1_ymax = bbox1\n",
    "    bbox2_xmin, bbox2_ymin, bbox2_xmax, bbox2_ymax = bbox2\n",
    "    x_dist = min(abs(bbox2_xmin-bbox1_xmax), abs(bbox2_xmax-bbox1_xmin))\n",
    "    y_dist = min(abs(bbox2_ymin-bbox1_ymax), abs(bbox2_ymax-bbox1_ymin))\n",
    "        \n",
    "    #define distance if one object is inside the other\n",
    "    if (bbox2_xmin <= bbox1_xmin) and (bbox2_ymin <= bbox1_ymin) and (bbox2_xmax >= bbox1_xmax) and (bbox2_ymax >= bbox1_ymax):\n",
    "        return True\n",
    "    elif (bbox1_xmin <= bbox2_xmin) and (bbox1_ymin <= bbox2_ymin) and (bbox1_xmax >= bbox2_xmax) and (bbox1_ymax >= bbox2_ymax):\n",
    "        return True\n",
    "    #determine if both bboxes are close to each other in 1d, and equal or smaller length in the other\n",
    "    elif (x_dist <= dist_limit) and (bbox1_ymin <= bbox2_ymin) and (bbox1_ymax >= bbox2_ymax): #bb1 bigger\n",
    "        return True\n",
    "    elif (x_dist <= dist_limit) and (bbox2_ymin <= bbox1_ymin) and (bbox2_ymax >= bbox1_ymax): #bb2 bigger\n",
    "        return True\n",
    "    elif (y_dist <= dist_limit) and (bbox1_xmin <= bbox2_xmin) and (bbox1_xmax >= bbox2_xmax): #bb1 bigger\n",
    "        return True\n",
    "    elif (y_dist <= dist_limit) and (bbox2_xmin <= bbox1_xmin) and (bbox2_xmax >= bbox1_xmax): #bb2 bigger\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "\n",
    "def calculate_diameter(bbox, resolution = 0.6): #used\n",
    "    \"\"\" Calculate the diameter of a given bounding bbox (in Pascal Voc Format) for imagery of a given resolution\n",
    "    Arg:\n",
    "    bbox(list): a list of the (xmin, ymin, xmax, ymax) coordinates for box. Utm coordinates are provided as [nw_x_utm, se_y_utm, se_x_utm, nw_y_utm] to conform with Pascal Voc Format.\n",
    "    resolution(float): the (gsd) resolution of the imagery\n",
    "    Returns:\n",
    "    (diameter): the diameter of the bbox of interest\n",
    "    \n",
    "                [#minx, #maxy, #maxx, #minx]\n",
    "    \"\"\"\n",
    "    obj_xmin, obj_ymin, obj_xmax, obj_ymax = bbox\n",
    "    obj_width = obj_xmax - obj_xmin\n",
    "    obj_height = obj_ymax - obj_ymin\n",
    "    diameter = min(obj_width, obj_height) * resolution #meter\n",
    "    return diameter\n",
    "\n",
    "\n",
    "def calc_dist_from_latlon_pair(coord1, coord2):\n",
    "    \"\"\"Given a two coordinate pairs, calculate the haversine distance between the points\n",
    "    Args:\n",
    "    coord1(array): numpy array of the lat,lon for coordinate 1\n",
    "    coord2(array): numpy array of the lat,lon for coordinate 2\n",
    "    Returns: the distance between coord1 and 2\n",
    "    \"\"\"\n",
    "    c1_in_radians = [radians(_) for _ in coord1]\n",
    "    c2_in_radians = [radians(_) for _ in coord2]\n",
    "    dist = haversine_distances([c1_in_radians, c2_in_radians])\n",
    "    return(dist[1][0])  # return in radians\n",
    "\n",
    "def diam_from_width_height(poly):\n",
    "    \"\"\"Calculate the diameter of a polygon,calcualated as the lesser of the width and the height,\n",
    "    using the lat/lon coordinates. \n",
    "    Args:\n",
    "    poly(polygon): shapely polygon\n",
    "    Returns: \n",
    "    diameter(float):diameter in meters\n",
    "    \"\"\"\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html#:~:text=The%20Haversine%20(or%20great%20circle,the%20longitude%2C%20given%20in%20radians.\n",
    "    #less favorable method of height estimation\n",
    "    coords = np.asarray(poly.exterior.coords.xy) #up,left; low,left; low,right; up,right; up,left;\n",
    "    coords = np.flip(coords,0) #give coords as lat, lon\n",
    "    width = calc_width_from_latlon_pair(coords[:,0], coords[:,3])  #up,left #up,right\n",
    "    height = calc_dist_from_latlon_pair(coords[:,0], coords[:,1])  #up,left #low,left\n",
    "    diameter = min(width, height) * 6371000 #multiply by Earth radius to get meters\n",
    "    return diameter\n",
    "\n",
    "\n",
    "def merge_tile_annotations(tile_characteristics, tiles_xml_dir, tiles_xml_list=None, distance_limit=5): #used\n",
    "    # References:\n",
    "    # https: // answers.opencv.org / question / 231263 / merging - nearby - rectanglesedited /\n",
    "    # https://stackoverflow.com/questions/55593506/merge-the-bounding-boxes-near-by-into-one\n",
    "    # specify tiles_xml_list\n",
    "    if tiles_xml_list is None: # if tiles_xml_list not provided, specify the tiles xml list\n",
    "        tiles_xml_list = os.listdir(tiles_xml_dir)\n",
    "    # lists for geosons/geodatabase\n",
    "    tile_names = []\n",
    "    chip_names = []\n",
    "    object_class = []\n",
    "    merged_bbox = []\n",
    "    geometry = []  \n",
    "    minx_pixels = []\n",
    "    miny_pixels = []\n",
    "    maxx_pixels = []\n",
    "    maxy_pixels = []\n",
    "    utm_projection = []\n",
    "    nw_x_utms = []\n",
    "    nw_y_utms = []\n",
    "    se_x_utms = []\n",
    "    se_y_utms = []\n",
    "    centroid_lons = []\n",
    "    centroid_lats = []\n",
    "    nw_lats = []\n",
    "    nw_lons = []\n",
    "    se_lats = []\n",
    "    se_lons = []\n",
    "    diameter = []\n",
    "    for tile_xml in tqdm(tiles_xml_list): # iterate over tiles\n",
    "        # save bboxes and characteristics\n",
    "        trunc_diff_objs_bboxes = []\n",
    "        trunc_diff_objs_characteristics = []\n",
    "        remaining_objs_bboxes = []\n",
    "        remaining_objs_characteristics = []\n",
    "        # get tile name / tile xml path\n",
    "        tile_name = os.path.splitext(tile_xml)[0]\n",
    "        tile_xml_path = os.path.join(tiles_xml_dir, tile_xml)\n",
    "        # load tile characteristics\n",
    "        tile_characteristics_subset = tile_characteristics[tile_characteristics.loc[:,\"tile_name\"] == tile_name]\n",
    "        #get utm coords\n",
    "        tile_utmx_array = np.linspace(float(tile_characteristics_subset[\"nw_x_utm_tile_coord\"].values[0]), \n",
    "                                      float(tile_characteristics_subset[\"se_x_utm_tile_coord\"].values[0]),\n",
    "                                      int(tile_characteristics_subset[\"tile_width\"].values[0]))\n",
    "        tile_utmy_array = np.linspace(float(tile_characteristics_subset[\"nw_y_utm_tile_coord\"].values[0]),\n",
    "                                      float(tile_characteristics_subset[\"se_y_utm_tile_coord\"].values[0]),\n",
    "                                      int(tile_characteristics_subset[\"tile_height\"].values[0]))\n",
    "        utm_proj = tile_characteristics_subset[\"utm_projection\"].values[0]\n",
    "        # load each xml\n",
    "        tree = et.parse(tile_xml_path)\n",
    "        root = tree.getroot()\n",
    "        for obj in root.iter('object'):\n",
    "            xmlbox = obj.find('bndbox') #get the bboxes\n",
    "            obj_xmin = xmlbox.find('xmin').text\n",
    "            obj_ymin = xmlbox.find('ymin').text\n",
    "            obj_xmax = xmlbox.find('xmax').text\n",
    "            obj_ymax = xmlbox.find('ymax').text\n",
    "            # get truncated bboxes/characteristics\n",
    "            if (int(obj.find('difficult').text) == 1) or (int(obj.find('truncated').text) == 1):\n",
    "                trunc_diff_objs_bboxes.append([obj_xmin, obj_ymin, obj_xmax, obj_ymax])\n",
    "                trunc_diff_objs_characteristics.append([obj.find('chip_name').text, obj.find('name').text,\n",
    "                                                        obj.find('pose').text, obj.find('truncated').text,\n",
    "                                                        obj.find('difficult').text])\n",
    "            else: #get remaining bboxes/characteristics\n",
    "                remaining_objs_bboxes.append([obj_xmin, obj_ymin, obj_xmax, obj_ymax])\n",
    "                remaining_objs_characteristics.append([obj.find('chip_name').text, obj.find('name').text,\n",
    "                                                       obj.find('pose').text, obj.find('truncated').text,\n",
    "                                                       obj.find('difficult').text])\n",
    "        \n",
    "        # Add merge bboxes\n",
    "        trunc_diff_objs_bboxes = np.array(trunc_diff_objs_bboxes).astype(np.int32)\n",
    "        trunc_diff_objs_bboxes = trunc_diff_objs_bboxes.tolist()\n",
    "        merged_bools, merged_characteristics, merged_bboxes = merge_algo(trunc_diff_objs_characteristics,\n",
    "                                                                         trunc_diff_objs_bboxes, distance_limit)\n",
    "\n",
    "        for j, (merged_bool, char, bbox) in enumerate(zip(merged_bools, merged_characteristics, merged_bboxes)):\n",
    "            tile_names.append(tile_name) \n",
    "            chip_names.append(char[0])\n",
    "            object_class.append(char[1])\n",
    "            # state whether bbox were merged\n",
    "            merged_bbox.append(merged_bool)\n",
    "            # pixel coordinates, 0 indexed\n",
    "            minx = bbox[0] - 1\n",
    "            miny = bbox[1] - 1\n",
    "            maxx = bbox[2] - 1\n",
    "            maxy = bbox[3] - 1 \n",
    "\n",
    "            minx_pixels.append(minx)\n",
    "            miny_pixels.append(miny)\n",
    "            maxx_pixels.append(maxx)\n",
    "            maxy_pixels.append(maxy)\n",
    "            # geospatial data\n",
    "            utm_projection.append(utm_proj)\n",
    "            nw_x_utm = tile_utmx_array[minx]\n",
    "            nw_y_utm = tile_utmy_array[miny]\n",
    "            se_x_utm = tile_utmx_array[maxx]\n",
    "            se_y_utm = tile_utmy_array[maxy]\n",
    "            nw_x_utms.append(nw_x_utm)\n",
    "            nw_y_utms.append(nw_y_utm)\n",
    "            se_x_utms.append(se_x_utm)\n",
    "            se_y_utms.append(se_y_utm)\n",
    "            nw_lon, nw_lat = transform_point_utm_to_wgs84(utm_proj, nw_x_utm, nw_y_utm)\n",
    "            se_lon, se_lat = transform_point_utm_to_wgs84(utm_proj, se_x_utm, se_y_utm)\n",
    "            nw_lons.append(nw_lon)\n",
    "            nw_lats.append(nw_lat)\n",
    "            se_lons.append(se_lon)\n",
    "            se_lats.append(se_lat)\n",
    "            geometry.append(Polygon([(nw_lon, nw_lat), (nw_lon, se_lat), \n",
    "                                     (se_lon, se_lat), (se_lon, nw_lat)]))\n",
    "            #add centroid\n",
    "            utmcentroidx=nw_x_utm+(se_x_utm-nw_x_utm)/2\n",
    "            utmcentroidy=se_y_utm+(nw_y_utm-se_y_utm)/2\n",
    "            centroid_lon, centroid_lat = transform_point_utm_to_wgs84(utm_proj, utmcentroidx, utmcentroidy)\n",
    "            centroid_lons.append(centroid_lon)\n",
    "            centroid_lats.append(centroid_lat)\n",
    "            #calculate diameter\n",
    "            diameter.append(calculate_diameter(bbox))\n",
    "            \n",
    "        #Add remaining bboxes\n",
    "        remaining_objs_bboxes = np.array(remaining_objs_bboxes).astype(np.int32)\n",
    "        remaining_objs_bboxes = remaining_objs_bboxes.tolist()\n",
    "        for j, (char, bbox) in enumerate(zip(remaining_objs_characteristics, remaining_objs_bboxes)):\n",
    "            tile_names.append(tile_name)\n",
    "            chip_names.append(char[0])\n",
    "            object_class.append(char[1])\n",
    "            # state whether bbox were merged\n",
    "            merged_bbox.append(False)\n",
    "            # pixel coordinates, 0 indexed\n",
    "            minx = bbox[0] - 1\n",
    "            miny = bbox[1] - 1\n",
    "            maxx = bbox[2] - 1\n",
    "            maxy = bbox[3] - 1\n",
    "            minx_pixels.append(minx)\n",
    "            miny_pixels.append(miny)\n",
    "            maxx_pixels.append(maxx)\n",
    "            maxy_pixels.append(maxy)\n",
    "            #geospatial data\n",
    "            utm_projection.append(utm_proj)\n",
    "            nw_x_utm = tile_utmx_array[minx]\n",
    "            nw_y_utm = tile_utmy_array[miny]\n",
    "            se_x_utm = tile_utmx_array[maxx]\n",
    "            se_y_utm = tile_utmy_array[maxy]\n",
    "            nw_x_utms.append(nw_x_utm)\n",
    "            nw_y_utms.append(nw_y_utm)\n",
    "            se_x_utms.append(se_x_utm)\n",
    "            se_y_utms.append(se_y_utm)\n",
    "            nw_lon, nw_lat = transform_point_utm_to_wgs84(utm_proj, nw_x_utm, nw_y_utm)\n",
    "            se_lon, se_lat = transform_point_utm_to_wgs84(utm_proj, se_x_utm, se_y_utm)\n",
    "            nw_lons.append(nw_lon)\n",
    "            nw_lats.append(nw_lat)\n",
    "            se_lons.append(se_lon)\n",
    "            se_lats.append(se_lat)\n",
    "            geometry.append(Polygon([(nw_lon, nw_lat), (nw_lon, se_lat), (se_lon, se_lat), (se_lon, nw_lat)]))\n",
    "            #add centroid\n",
    "            utmcentroidx=nw_x_utm+(se_x_utm-nw_x_utm)/2\n",
    "            utmcentroidy=se_y_utm+(nw_y_utm-se_y_utm)/2\n",
    "            centroid_lon, centroid_lat = transform_point_utm_to_wgs84(utm_proj, utmcentroidx, utmcentroidy)\n",
    "            centroid_lons.append(centroid_lon)\n",
    "            centroid_lats.append(centroid_lat)\n",
    "            #calculate diameter\n",
    "            diameter.append(calculate_diameter(bbox))\n",
    "            \n",
    "    #create geodatabase\n",
    "    gdf = gpd.GeoDataFrame({\"object_class\": object_class, 'tile_name': tile_names,'image_name': chip_names, \n",
    "            \"nw_x_pixel_object_coord\": minx_pixels, \"nw_y_pixel_object_coord\": miny_pixels, #min lon/lat\n",
    "            \"se_x_pixel_object_coord\": maxx_pixels, \"se_y_pixel_object_coord\": maxy_pixels, #max lat\n",
    "            \"utm_projection\": utm_projection,\n",
    "            \"nw_x_utm_object_coord\": nw_x_utms, \"nw_y_utm_object_coord\": nw_y_utms, #utm min\n",
    "            \"se_x_utm_object_coord\": se_x_utms, \"se_y_utm_object_coord\": se_y_utms, #utm max             \n",
    "            \"nw_lat_object_coord\": nw_lats, \"nw_lon_object_coord\": nw_lons,#min lon/lat\n",
    "            \"se_lat_object_coord\": se_lats, \"se_lon_object_coord\": se_lons, #min lon/lat\n",
    "            \"centroid_lon_object_coord\": centroid_lons, \"centroid_lat_object_coord\": centroid_lats, #centroid\n",
    "            'geometry': geometry, 'diameter': diameter, 'merged_bbox': merged_bbox})\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "zR9ZbuQCH7FX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "64489d1f-e71a-44b5-92f6-2088781ca096",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 77.2MB/s]\n",
      "Ultralytics YOLOv8.0.145  Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "\n",
      "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
      "100% 165k/165k [00:00<00:00, 7.46MB/s]\n",
      "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 365.8ms\n",
      "Speed: 13.7ms preprocess, 365.8ms inference, 431.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image with YOLOv8n\n",
    "#!yolo predict model=yolov8.pt source='https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use stream=True for processing long videos or large datasets to efficiently manage memory. When stream=False, the results for all frames or data points are stored in memory, which can quickly add up and cause out-of-memory errors for large inputs. In contrast, stream=True utilizes a generator, which only keeps the results of the current frame or data point in memory, significantly reducing memory consumption and preventing out-of-memory issues.\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model(['im1.jpg', 'im2.jpg'], stream=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkAzDWJ7cWTr"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLOv8 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "yolov8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
